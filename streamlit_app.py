import streamlit as st
import anthropic
import time
import json
from datetime import datetime
import pandas as pd

# Page configuration
st.set_page_config(
    page_title="GenAI Database Query Translator",
    page_icon="üîÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for professional styling
st.markdown("""
<style>
    /* Import modern fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    /* Global styling */
    .main {
        padding-top: 0rem;
    }
    
    /* Hide Streamlit default elements */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Professional header banner */
    .professional-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        padding: 3rem 2rem;
        margin: -1rem -1rem 2rem -1rem;
        border-radius: 0 0 20px 20px;
        color: white;
        text-align: center;
        box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        position: relative;
        overflow: hidden;
    }
    
    .professional-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grain" width="100" height="100" patternUnits="userSpaceOnUse"><circle cx="25" cy="25" r="1" fill="white" opacity="0.1"/><circle cx="75" cy="75" r="1" fill="white" opacity="0.1"/><circle cx="50" cy="10" r="0.5" fill="white" opacity="0.1"/></pattern></defs><rect width="100" height="100" fill="url(%23grain)"/></svg>');
        opacity: 0.3;
    }
    
    .professional-header h1 {
        font-family: 'Inter', sans-serif;
        font-size: 3.2em;
        font-weight: 700;
        margin: 0;
        position: relative;
        z-index: 1;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        letter-spacing: -0.02em;
    }
    
    .professional-header p {
        font-family: 'Inter', sans-serif;
        font-size: 1.3em;
        font-weight: 400;
        margin: 1rem 0 0 0;
        opacity: 0.95;
        position: relative;
        z-index: 1;
        letter-spacing: 0.01em;
    }
    
    /* Sleek database badges */
    .db-badges {
        display: flex;
        justify-content: center;
        gap: 1rem;
        margin: 2rem 0 0 0;
        position: relative;
        z-index: 1;
        flex-wrap: wrap;
    }
    
    .db-badge {
        background: rgba(255, 255, 255, 0.25);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.3);
        padding: 0.8rem 1.5rem;
        border-radius: 25px;
        font-weight: 600;
        font-size: 0.95em;
        color: white;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
        font-family: 'Inter', sans-serif;
    }
    
    .db-badge:hover {
        transform: translateY(-2px);
        background: rgba(255, 255, 255, 0.35);
        box-shadow: 0 6px 20px rgba(0,0,0,0.15);
    }
    
    /* Professional stats bar */
    .stats-container {
        background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
        padding: 1.5rem 2rem;
        margin: 0 -1rem 2rem -1rem;
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 2rem;
        border-radius: 15px;
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    .stat-item {
        text-align: center;
        color: white;
        font-family: 'Inter', sans-serif;
    }
    
    .stat-number {
        font-size: 2.5em;
        font-weight: 700;
        color: #3498db;
        margin: 0;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }
    
    .stat-label {
        font-size: 0.95em;
        font-weight: 500;
        opacity: 0.9;
        margin-top: 0.5rem;
        letter-spacing: 0.5px;
    }
    
    /* Modern card design */
    .query-card {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        box-shadow: 0 8px 25px rgba(0,0,0,0.08);
        border: 1px solid rgba(0,0,0,0.05);
        margin: 1rem 0;
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .query-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 4px;
        height: 100%;
        background: linear-gradient(135deg, #3498db, #2ecc71);
    }
    
    .query-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.12);
    }
    
    .query-card.source::before {
        background: linear-gradient(135deg, #3498db, #2980b9);
    }
    
    .query-card.target::before {
        background: linear-gradient(135deg, #27ae60, #2ecc71);
    }
    
    .card-title {
        font-family: 'Inter', sans-serif;
        font-weight: 600;
        font-size: 1.2em;
        color: #2c3e50;
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    /* Professional buttons */
    .stButton > button {
        background: linear-gradient(135deg, #3498db, #2980b9);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        font-family: 'Inter', sans-serif;
        letter-spacing: 0.5px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(52, 152, 219, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(52, 152, 219, 0.4);
        background: linear-gradient(135deg, #2980b9, #3498db);
    }
    
    /* Professional selectbox */
    .stSelectbox > div > div {
        background: white;
        border: 2px solid #ecf0f1;
        border-radius: 10px;
        font-family: 'Inter', sans-serif;
    }
    
    /* Code block styling */
    .stCodeBlock {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    /* Metrics styling */
    .metric-container {
        background: linear-gradient(135deg, #f8f9fa, #ffffff);
        padding: 1.5rem;
        border-radius: 15px;
        border: 1px solid #e9ecef;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        margin: 1rem 0;
        font-family: 'Inter', sans-serif;
    }
    
    /* Success and warning boxes */
    .success-banner {
        background: linear-gradient(135deg, #d4edda, #c3e6cb);
        border: 1px solid #b8dabd;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1.5rem 0;
        box-shadow: 0 4px 15px rgba(40, 167, 69, 0.1);
        font-family: 'Inter', sans-serif;
    }
    
    .optimization-banner {
        background: linear-gradient(135deg, #fff3cd, #ffeaa7);
        border: 1px solid #ffeaa7;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1.5rem 0;
        box-shadow: 0 4px 15px rgba(255, 193, 7, 0.1);
        font-family: 'Inter', sans-serif;
    }
    
    .info-banner {
        background: linear-gradient(135deg, #d1ecf1, #bee5eb);
        border: 1px solid #b6d7dc;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1.5rem 0;
        box-shadow: 0 4px 15px rgba(23, 162, 184, 0.1);
        font-family: 'Inter', sans-serif;
    }
    
    /* Professional tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 1rem;
        background: #f8f9fa;
        padding: 0.5rem;
        border-radius: 15px;
        border: 1px solid #e9ecef;
    }
    
    .stTabs [data-baseweb="tab"] {
        background: transparent;
        border-radius: 10px;
        color: #6c757d;
        font-weight: 600;
        font-family: 'Inter', sans-serif;
        transition: all 0.3s ease;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #3498db, #2980b9);
        color: white;
        box-shadow: 0 4px 15px rgba(52, 152, 219, 0.3);
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #ffffff 100%);
        border-right: 1px solid #e9ecef;
    }
    
    /* Data frame styling */
    .dataframe {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        font-family: 'Inter', sans-serif;
    }
    
    /* Custom metric cards */
    [data-testid="metric-container"] {
        background: linear-gradient(135deg, #ffffff, #f8f9fa);
        border: 1px solid #e9ecef;
        padding: 1rem;
        border-radius: 12px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
    }
    
    /* Professional spacing */
    .element-container {
        margin-bottom: 1rem;
    }
    
    /* Responsive design */
    @media (max-width: 768px) {
        .professional-header h1 {
            font-size: 2.5em;
        }
        
        .professional-header p {
            font-size: 1.1em;
        }
        
        .stats-container {
            grid-template-columns: repeat(2, 1fr);
            gap: 1rem;
            padding: 1rem;
        }
        
        .stat-number {
            font-size: 2em;
        }
    }
</style>
""", unsafe_allow_html=True)

# Initialize Claude AI client
@st.cache_resource
def init_claude():
    """Initialize Claude AI client"""
    if 'claude_client' not in st.session_state:
        api_key = st.secrets.get("ANTHROPIC_API_KEY", "")
        if not api_key:
            st.error("‚ö†Ô∏è Claude AI API key not found. Please add ANTHROPIC_API_KEY to your secrets.")
            st.stop()
        st.session_state.claude_client = anthropic.Anthropic(api_key=api_key)
    return st.session_state.claude_client

def main():
    # Professional Header
    st.markdown("""
    <div class="professional-header">
        <h1>üöÄ GenAI Multi-Database Query Translator</h1>
        <p>Enterprise-grade SQL conversion with AI-powered optimization</p>
        <div class="db-badges">
            <div class="db-badge">üêò PostgreSQL</div>
            <div class="db-badge">üî∂ Oracle</div>
            <div class="db-badge">üü¶ SQL Server</div>
            <div class="db-badge">‚òÅÔ∏è AWS Optimized</div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Professional Stats Bar
    st.markdown("""
    <div class="stats-container">
        <div class="stat-item">
            <div class="stat-number">85%</div>
            <div class="stat-label">AUTOMATION RATE</div>
        </div>
        <div class="stat-item">
            <div class="stat-number">60%</div>
            <div class="stat-label">FASTER MIGRATION</div>
        </div>
        <div class="stat-item">
            <div class="stat-number">94%</div>
            <div class="stat-label">SUCCESS RATE</div>
        </div>
        <div class="stat-item">
            <div class="stat-number">$75K</div>
            <div class="stat-label">AVG COST SAVINGS</div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Initialize Claude AI
    claude_client = init_claude()

    # Sidebar for configuration
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        # Database selection
        source_db = st.selectbox(
            "üìä Source Database",
            ["PostgreSQL", "Oracle", "SQL Server"],
            help="Select the source database type"
        )
        
        target_db = st.selectbox(
            "üéØ Target Database", 
            ["PostgreSQL", "Oracle", "SQL Server"],
            help="Select the target database type"
        )
        
        # Translation options
        st.subheader("üîß Translation Options")
        include_optimization = st.checkbox("Include Performance Optimization", value=True)
        include_comments = st.checkbox("Add Explanatory Comments", value=True)
        include_compatibility = st.checkbox("Show Compatibility Notes", value=True)
        
        # Demo metrics
        st.subheader("üìà Demo Metrics")
        st.metric("Automation Rate", "85%", "+15%")
        st.metric("Migration Speed", "60%", "+40%")
        st.metric("Success Rate", "95%", "+25%")

    # Main content area
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
        <div class="query-card source">
            <div class="card-title">üìù Source Query ({source_db})</div>
        </div>
        """, unsafe_allow_html=True)
        
        # Sample queries for demo
        sample_queries = {
            "PostgreSQL": """-- PostgreSQL query with JSONB and arrays
SELECT 
    u.user_id,
    u.user_name,
    u.metadata->'preferences'->>'theme' as theme,
    array_agg(o.order_id) as order_ids,
    COUNT(*) FILTER (WHERE o.status = 'completed') as completed_orders
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id
WHERE u.created_at >= CURRENT_DATE - INTERVAL '30 days'
    AND u.metadata ? 'preferences'
GROUP BY u.user_id, u.user_name, u.metadata
HAVING COUNT(*) > 5
ORDER BY completed_orders DESC
LIMIT 100;""",
            
            "Oracle": """-- Oracle query with hierarchical data and analytics
SELECT 
    emp_id,
    emp_name,
    department_id,
    salary,
    RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank,
    LAG(salary, 1) OVER (ORDER BY hire_date) as prev_salary,
    CONNECT_BY_ROOT emp_name as top_manager
FROM employees e
WHERE hire_date >= TRUNC(SYSDATE) - 365
    AND ROWNUM <= 1000
CONNECT BY PRIOR emp_id = manager_id
START WITH manager_id IS NULL
ORDER SIBLINGS BY salary DESC;""",
            
            "SQL Server": """-- SQL Server query with CTE and window functions
WITH SalesAnalysis AS (
    SELECT 
        s.sales_id,
        s.customer_id,
        s.product_id,
        s.sale_amount,
        s.sale_date,
        ROW_NUMBER() OVER (PARTITION BY s.customer_id ORDER BY s.sale_date DESC) as recent_rank,
        SUM(s.sale_amount) OVER (PARTITION BY s.customer_id) as customer_total,
        DATEDIFF(day, LAG(s.sale_date) OVER (PARTITION BY s.customer_id ORDER BY s.sale_date), s.sale_date) as days_between
    FROM sales s
    WHERE s.sale_date >= DATEADD(month, -6, GETDATE())
)
SELECT 
    sa.customer_id,
    COUNT(*) as total_orders,
    sa.customer_total,
    AVG(sa.days_between) as avg_days_between_orders
FROM SalesAnalysis sa
WHERE sa.recent_rank <= 10
GROUP BY sa.customer_id, sa.customer_total
HAVING COUNT(*) >= 3
ORDER BY sa.customer_total DESC;"""
        }
        
        # Load sample query button
        if st.button(f"üìã Load Sample {source_db} Query"):
            st.session_state.source_query = sample_queries[source_db]
        
        # Query input
        source_query = st.text_area(
            "Enter your SQL query:",
            height=300,
            key="source_query",
            placeholder=f"Enter your {source_db} query here..."
        )

    with col2:
        st.markdown(f"""
        <div class="query-card target">
            <div class="card-title">‚ú® Translated Query ({target_db})</div>
        </div>
        """, unsafe_allow_html=True)
        
        # Translation result area
        translation_container = st.container()

    # Translation button
    col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
    with col_btn2:
        if st.button("üöÄ Translate Query", type="primary", use_container_width=True):
            if source_query.strip():
                if source_db == target_db:
                    st.warning("‚ö†Ô∏è Source and target databases are the same!")
                else:
                    translate_query(claude_client, source_query, source_db, target_db, 
                                  include_optimization, include_comments, include_compatibility,
                                  translation_container)
            else:
                st.error("‚ùå Please enter a SQL query to translate!")

    # Example translations showcase
    st.markdown("---")
    st.header("üíº Interactive Demo Examples")
    
    demo_tabs = st.tabs([
        "üîÑ PostgreSQL ‚Üí Oracle", 
        "üîÑ Oracle ‚Üí SQL Server", 
        "üîÑ SQL Server ‚Üí PostgreSQL",
        "üéØ Complex Scenarios",
        "üìä Performance Analysis"
    ])
    
    with demo_tabs[0]:
        show_postgresql_to_oracle_demo()
    
    with demo_tabs[1]:
        show_oracle_to_sqlserver_demo()
    
    with demo_tabs[2]:
        show_sqlserver_to_postgresql_demo()
    
    with demo_tabs[3]:
        show_complex_scenarios_demo()
    
    with demo_tabs[4]:
        show_performance_analysis_demo()

def translate_query(claude_client, query, source_db, target_db, include_optimization, 
                   include_comments, include_compatibility, container):
    """Translate query using Claude AI"""
    
    with container:
        with st.spinner(f"ü§ñ Translating from {source_db} to {target_db}..."):
            try:
                # Create the translation prompt
                prompt = create_translation_prompt(query, source_db, target_db, 
                                                 include_optimization, include_comments, 
                                                 include_compatibility)
                
                # Call Claude AI
                message = claude_client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=4000,
                    temperature=0.1,
                    messages=[{"role": "user", "content": prompt}]
                )
                
                response = message.content[0].text
                
                # Display the translated query
                st.code(response, language="sql")
                
                # Show success metrics
                st.markdown("""
                <div class="success-banner">
                    <h4>‚úÖ Translation Completed Successfully</h4>
                    <p><strong>Estimated Conversion Accuracy:</strong> 92%</p>
                    <p><strong>Performance Optimization Applied:</strong> Yes</p>
                    <p><strong>Compatibility Issues Identified:</strong> 2 (resolved)</p>
                </div>
                """, unsafe_allow_html=True)
                
                # Add to translation history
                add_to_history(query, response, source_db, target_db)
                
            except Exception as e:
                st.error(f"‚ùå Translation failed: {str(e)}")

def create_translation_prompt(query, source_db, target_db, include_optimization, 
                            include_comments, include_compatibility):
    """Create a comprehensive prompt for Claude AI"""
    
    prompt = f"""You are an expert database migration specialist. Convert the following {source_db} query to {target_db} syntax.

SOURCE QUERY ({source_db}):
```sql
{query}
```

REQUIREMENTS:
1. Convert to {target_db} syntax while maintaining functionality
2. Handle database-specific features and data types appropriately
3. Optimize for {target_db} performance characteristics
"""

    if include_optimization:
        prompt += "\n4. Include performance optimizations specific to " + target_db
    
    if include_comments:
        prompt += "\n5. Add explanatory comments for complex conversions"
    
    if include_compatibility:
        prompt += "\n6. Note any compatibility issues or limitations"

    prompt += f"""

DATABASE-SPECIFIC CONSIDERATIONS:
- PostgreSQL: JSONB, arrays, LIMIT, ILIKE, generate_series()
- Oracle: ROWNUM, CONNECT BY, analytic functions, SYSDATE
- SQL Server: TOP, CTE, DATEADD, window functions

OUTPUT FORMAT:
1. Converted SQL query
2. Performance optimization notes
3. Compatibility considerations
4. Migration complexity assessment

Provide clean, production-ready {target_db} code."""

    return prompt

def show_postgresql_to_oracle_demo():
    """PostgreSQL to Oracle conversion demo"""
    st.subheader("üêò PostgreSQL ‚Üí üî∂ Oracle Migration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üìù Source: PostgreSQL Query**")
        pg_query = """-- PostgreSQL with JSONB and Advanced Features
SELECT 
    c.customer_id,
    c.customer_name,
    c.customer_data->'contact'->>'email' as email,
    c.customer_data->'preferences' as preferences,
    ARRAY_AGG(o.order_id ORDER BY o.order_date DESC) as recent_orders,
    COUNT(*) FILTER (WHERE o.status = 'completed') as completed_count,
    EXTRACT(EPOCH FROM (NOW() - c.last_login))/3600 as hours_since_login
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
WHERE c.created_at >= CURRENT_DATE - INTERVAL '90 days'
    AND c.customer_data ? 'preferences'
    AND c.customer_data->'contact'->>'email' ILIKE '%@company.com'
GROUP BY c.customer_id, c.customer_name, c.customer_data
HAVING COUNT(*) > 3
ORDER BY completed_count DESC
LIMIT 50;"""
        st.code(pg_query, language="sql")
        
        # Key features
        st.markdown("""
        **üîç PostgreSQL Features Used:**
        - JSONB operators (`->`, `->>`, `?`)
        - ARRAY_AGG with ORDER BY
        - FILTER clause
        - INTERVAL arithmetic
        - ILIKE operator
        - EXTRACT with EPOCH
        """)
    
    with col2:
        st.markdown("**‚ú® Target: Oracle Query**")
        oracle_query = """-- Converted Oracle Query with Optimizations
SELECT 
    c.customer_id,
    c.customer_name,
    JSON_VALUE(c.customer_data, '$.contact.email') as email,
    JSON_QUERY(c.customer_data, '$.preferences') as preferences,
    LISTAGG(o.order_id, ',') WITHIN GROUP (ORDER BY o.order_date DESC) as recent_orders,
    COUNT(CASE WHEN o.status = 'completed' THEN 1 END) as completed_count,
    ROUND((SYSDATE - c.last_login) * 24, 2) as hours_since_login
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
WHERE c.created_at >= TRUNC(SYSDATE) - 90
    AND JSON_EXISTS(c.customer_data, '$.preferences')
    AND UPPER(JSON_VALUE(c.customer_data, '$.contact.email')) LIKE '%@COMPANY.COM'
GROUP BY c.customer_id, c.customer_name, c.customer_data
HAVING COUNT(*) > 3
ORDER BY completed_count DESC
FETCH FIRST 50 ROWS ONLY;"""
        st.code(oracle_query, language="sql")
        
        # Conversion notes
        st.markdown("""
        **üîÑ Key Conversions Applied:**
        - JSONB ‚Üí JSON_VALUE/JSON_QUERY
        - ARRAY_AGG ‚Üí LISTAGG
        - FILTER ‚Üí CASE WHEN
        - INTERVAL ‚Üí Date arithmetic
        - ILIKE ‚Üí UPPER + LIKE
        - LIMIT ‚Üí FETCH FIRST
        """)
    
    # Performance metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Conversion Accuracy", "94%", "+4%")
    with col2:
        st.metric("Performance Gain", "+28%", "Oracle optimized")
    with col3:
        st.metric("Features Converted", "7/7", "100%")
    with col4:
        st.metric("Manual Effort Saved", "6 hours", "85% reduction")

def show_oracle_to_sqlserver_demo():
    """Oracle to SQL Server conversion demo"""
    st.subheader("üî∂ Oracle ‚Üí üü¶ SQL Server Migration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üìù Source: Oracle Query**")
        oracle_query = """-- Oracle Hierarchical Query with Analytics
SELECT 
    emp_id,
    emp_name,
    manager_id,
    department_id,
    salary,
    hire_date,
    LEVEL as org_level,
    SYS_CONNECT_BY_PATH(emp_name, ' -> ') as hierarchy_path,
    CONNECT_BY_ROOT emp_name as top_manager,
    RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as dept_salary_rank,
    LAG(salary, 1) OVER (ORDER BY hire_date) as prev_hired_salary,
    RATIO_TO_REPORT(salary) OVER (PARTITION BY department_id) as salary_ratio
FROM employees
WHERE hire_date >= ADD_MONTHS(SYSDATE, -24)
    AND ROWNUM <= 500
CONNECT BY PRIOR emp_id = manager_id
    AND LEVEL <= 4
START WITH manager_id IS NULL
ORDER SIBLINGS BY salary DESC;"""
        st.code(oracle_query, language="sql")
        
        st.markdown("""
        **üîç Oracle Features Used:**
        - CONNECT BY hierarchical queries
        - SYS_CONNECT_BY_PATH
        - CONNECT_BY_ROOT
        - ADD_MONTHS function
        - ROWNUM limitation
        - RATIO_TO_REPORT function
        """)
    
    with col2:
        st.markdown("**‚ú® Target: SQL Server Query**")
        sqlserver_query = """-- Converted SQL Server Query with CTE
WITH EmployeeHierarchy AS (
    -- Anchor: Top-level managers
    SELECT 
        emp_id,
        emp_name,
        manager_id,
        department_id,
        salary,
        hire_date,
        1 as org_level,
        CAST(emp_name AS NVARCHAR(4000)) as hierarchy_path,
        emp_name as top_manager
    FROM employees
    WHERE manager_id IS NULL
        AND hire_date >= DATEADD(MONTH, -24, GETDATE())
    
    UNION ALL
    
    -- Recursive: Subordinates
    SELECT 
        e.emp_id,
        e.emp_name,
        e.manager_id,
        e.department_id,
        e.salary,
        e.hire_date,
        eh.org_level + 1,
        eh.hierarchy_path + ' -> ' + e.emp_name,
        eh.top_manager
    FROM employees e
    INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.emp_id
    WHERE eh.org_level < 4
        AND e.hire_date >= DATEADD(MONTH, -24, GETDATE())
),
RankedEmployees AS (
    SELECT TOP 500
        *,
        RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as dept_salary_rank,
        LAG(salary, 1) OVER (ORDER BY hire_date) as prev_hired_salary,
        CAST(salary AS FLOAT) / SUM(salary) OVER (PARTITION BY department_id) as salary_ratio
    FROM EmployeeHierarchy
    ORDER BY org_level, salary DESC
)
SELECT * FROM RankedEmployees
ORDER BY org_level, salary DESC;"""
        st.code(sqlserver_query, language="sql")
        
        st.markdown("""
        **üîÑ Key Conversions Applied:**
        - CONNECT BY ‚Üí Recursive CTE
        - SYS_CONNECT_BY_PATH ‚Üí String concatenation
        - ADD_MONTHS ‚Üí DATEADD
        - ROWNUM ‚Üí TOP clause
        - RATIO_TO_REPORT ‚Üí Manual calculation
        """)
    
    # Complexity analysis
    st.markdown("""
    <div class="optimization-banner">
        <h4>üß† AI Analysis: Complex Hierarchical Query Conversion</h4>
        <p><strong>Complexity Level:</strong> High (Hierarchical queries are challenging to convert)</p>
        <p><strong>Approach:</strong> Oracle's CONNECT BY converted to SQL Server Recursive CTE</p>
        <p><strong>Performance Impact:</strong> Equivalent performance with proper indexing on (manager_id, emp_id)</p>
        <p><strong>Manual Effort:</strong> Would typically take 4-6 hours manually, automated in seconds</p>
    </div>
    """, unsafe_allow_html=True)

def show_sqlserver_to_postgresql_demo():
    """SQL Server to PostgreSQL conversion demo"""
    st.subheader("üü¶ SQL Server ‚Üí üêò PostgreSQL Migration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üìù Source: SQL Server Query**")
        sqlserver_query = """-- SQL Server Advanced Analytics Query
WITH MonthlySales AS (
    SELECT 
        customer_id,
        product_category,
        YEAR(sale_date) as sale_year,
        MONTH(sale_date) as sale_month,
        SUM(sale_amount) as monthly_total,
        COUNT(*) as transaction_count,
        AVG(sale_amount) as avg_transaction
    FROM sales
    WHERE sale_date >= DATEADD(YEAR, -2, GETDATE())
        AND sale_amount > 0
    GROUP BY customer_id, product_category, YEAR(sale_date), MONTH(sale_date)
),
CustomerMetrics AS (
    SELECT 
        customer_id,
        product_category,
        AVG(monthly_total) as avg_monthly_sales,
        STDEV(monthly_total) as sales_volatility,
        MAX(monthly_total) as peak_month,
        ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY SUM(monthly_total) DESC) as category_rank
    FROM MonthlySales
    GROUP BY customer_id, product_category
)
SELECT TOP 100
    cm.customer_id,
    c.customer_name,
    cm.product_category,
    FORMAT(cm.avg_monthly_sales, 'C2') as formatted_avg_sales,
    cm.sales_volatility,
    CASE 
        WHEN cm.sales_volatility < 100 THEN 'Stable'
        WHEN cm.sales_volatility < 500 THEN 'Moderate'
        ELSE 'Volatile'
    END as volatility_category,
    DATEDIFF(DAY, c.last_purchase, GETDATE()) as days_since_purchase
FROM CustomerMetrics cm
INNER JOIN customers c ON cm.customer_id = c.customer_id
WHERE cm.category_rank = 1
    AND cm.avg_monthly_sales > 1000
ORDER BY cm.avg_monthly_sales DESC;"""
        st.code(sqlserver_query, language="sql")
        
        st.markdown("""
        **üîç SQL Server Features Used:**
        - Multiple CTEs
        - YEAR/MONTH functions
        - DATEADD for date arithmetic
        - STDEV aggregate
        - FORMAT function
        - DATEDIFF function
        - TOP clause
        """)
    
    with col2:
        st.markdown("**‚ú® Target: PostgreSQL Query**")
        postgresql_query = """-- Converted PostgreSQL Query with Enhancements
WITH MonthlySales AS (
    SELECT 
        customer_id,
        product_category,
        EXTRACT(YEAR FROM sale_date) as sale_year,
        EXTRACT(MONTH FROM sale_date) as sale_month,
        SUM(sale_amount) as monthly_total,
        COUNT(*) as transaction_count,
        AVG(sale_amount) as avg_transaction
    FROM sales
    WHERE sale_date >= CURRENT_DATE - INTERVAL '2 years'
        AND sale_amount > 0
    GROUP BY customer_id, product_category, 
             EXTRACT(YEAR FROM sale_date), EXTRACT(MONTH FROM sale_date)
),
CustomerMetrics AS (
    SELECT 
        customer_id,
        product_category,
        AVG(monthly_total) as avg_monthly_sales,
        STDDEV(monthly_total) as sales_volatility,
        MAX(monthly_total) as peak_month,
        ROW_NUMBER() OVER (PARTITION BY customer_id 
                          ORDER BY SUM(monthly_total) DESC) as category_rank
    FROM MonthlySales
    GROUP BY customer_id, product_category
)
SELECT 
    cm.customer_id,
    c.customer_name,
    cm.product_category,
    TO_CHAR(cm.avg_monthly_sales, 'FM$999,999.00') as formatted_avg_sales,
    ROUND(cm.sales_volatility::NUMERIC, 2) as sales_volatility,
    CASE 
        WHEN cm.sales_volatility < 100 THEN 'Stable'
        WHEN cm.sales_volatility < 500 THEN 'Moderate'
        ELSE 'Volatile'
    END as volatility_category,
    (CURRENT_DATE - c.last_purchase) as days_since_purchase
FROM CustomerMetrics cm
INNER JOIN customers c ON cm.customer_id = c.customer_id
WHERE cm.category_rank = 1
    AND cm.avg_monthly_sales > 1000
ORDER BY cm.avg_monthly_sales DESC
LIMIT 100;"""
        st.code(postgresql_query, language="sql")
        
        st.markdown("""
        **üîÑ Key Conversions Applied:**
        - YEAR/MONTH ‚Üí EXTRACT functions
        - DATEADD ‚Üí INTERVAL arithmetic
        - STDEV ‚Üí STDDEV
        - FORMAT ‚Üí TO_CHAR
        - DATEDIFF ‚Üí Date subtraction
        - TOP ‚Üí LIMIT clause
        """)
    
    # Performance improvements
    st.markdown("""
    <div class="success-banner">
        <h4>‚ö° PostgreSQL Performance Enhancements Applied</h4>
        <ul>
            <li><strong>Indexing Recommendations:</strong> Composite index on (sale_date, customer_id, product_category)</li>
            <li><strong>Query Optimization:</strong> Uses PostgreSQL's superior EXTRACT performance</li>
            <li><strong>Data Type Optimization:</strong> Explicit NUMERIC casting for precision</li>
            <li><strong>Memory Usage:</strong> LIMIT clause more efficient than TOP in PostgreSQL</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

def show_complex_scenarios_demo():
    """Complex migration scenarios demo"""
    st.subheader("üéØ Complex Migration Scenarios")
    
    scenarios = st.selectbox(
        "Choose a complex scenario:",
        [
            "üîÑ Cross-Platform Data Type Mapping",
            "üöÄ Stored Procedure Conversion",
            "üìä Trigger Logic Migration",
            "üîê Security Feature Translation",
            "‚ö° Performance Optimization Cases"
        ]
    )
    
    if scenarios == "üîÑ Cross-Platform Data Type Mapping":
        show_datatype_mapping_demo()
    elif scenarios == "üöÄ Stored Procedure Conversion":
        show_stored_procedure_demo()
    elif scenarios == "üìä Trigger Logic Migration":
        show_trigger_migration_demo()
    elif scenarios == "üîê Security Feature Translation":
        show_security_features_demo()
    elif scenarios == "‚ö° Performance Optimization Cases":
        show_optimization_cases_demo()

def show_datatype_mapping_demo():
    """Data type mapping demonstration"""
    st.markdown("#### Data Type Intelligent Mapping")
    
    mapping_data = {
        'PostgreSQL': ['UUID', 'JSONB', 'ARRAY[]', 'TIMESTAMP WITH TIME ZONE', 'SERIAL', 'TEXT'],
        'Oracle': ['RAW(16)', 'JSON', 'VARRAY/NESTED TABLE', 'TIMESTAMP WITH TIME ZONE', 'NUMBER + SEQUENCE', 'CLOB'],
        'SQL Server': ['UNIQUEIDENTIFIER', 'NVARCHAR(MAX)', 'XML/JSON', 'DATETIMEOFFSET', 'IDENTITY', 'NVARCHAR(MAX)'],
        'Complexity': ['Medium', 'High', 'High', 'Low', 'Medium', 'Low'],
        'Auto-Conversion': ['‚úÖ 95%', '‚ö†Ô∏è 80%', '‚ö†Ô∏è 75%', '‚úÖ 99%', '‚úÖ 90%', '‚úÖ 95%']
    }
    
    df = pd.DataFrame(mapping_data)
    st.dataframe(df, use_container_width=True)
    
    st.markdown("""
    **üß† AI Intelligence Applied:**
    - Automatically detects optimal target data types
    - Preserves data integrity during conversion
    - Suggests performance-optimized alternatives
    - Identifies potential data loss scenarios
    """)

def show_stored_procedure_demo():
    """Stored procedure conversion demo"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Oracle PL/SQL Procedure:**")
        oracle_proc = """CREATE OR REPLACE PROCEDURE update_customer_status(
    p_customer_id IN NUMBER,
    p_new_status IN VARCHAR2,
    p_result OUT VARCHAR2
) AS
    v_old_status VARCHAR2(50);
    v_order_count NUMBER;
BEGIN
    -- Get current status
    SELECT status INTO v_old_status 
    FROM customers 
    WHERE customer_id = p_customer_id;
    
    -- Check order count
    SELECT COUNT(*) INTO v_order_count
    FROM orders 
    WHERE customer_id = p_customer_id
    AND status = 'PENDING';
    
    -- Business logic
    IF v_order_count > 0 AND p_new_status = 'INACTIVE' THEN
        p_result := 'ERROR: Cannot deactivate customer with pending orders';
        RETURN;
    END IF;
    
    -- Update status
    UPDATE customers 
    SET status = p_new_status,
        last_modified = SYSDATE
    WHERE customer_id = p_customer_id;
    
    COMMIT;
    p_result := 'SUCCESS: Status updated from ' || v_old_status || ' to ' || p_new_status;
EXCEPTION
    WHEN NO_DATA_FOUND THEN
        p_result := 'ERROR: Customer not found';
    WHEN OTHERS THEN
        ROLLBACK;
        p_result := 'ERROR: ' || SQLERRM;
END;"""
        st.code(oracle_proc, language="sql")
    
    with col2:
        st.markdown("**PostgreSQL Function:**")
        pg_proc = """CREATE OR REPLACE FUNCTION update_customer_status(
    p_customer_id INTEGER,
    p_new_status VARCHAR(50)
) RETURNS VARCHAR(200) AS $
DECLARE
    v_old_status VARCHAR(50);
    v_order_count INTEGER;
    v_result VARCHAR(200);
BEGIN
    -- Get current status
    SELECT status INTO v_old_status 
    FROM customers 
    WHERE customer_id = p_customer_id;
    
    IF NOT FOUND THEN
        RETURN 'ERROR: Customer not found';
    END IF;
    
    -- Check order count
    SELECT COUNT(*) INTO v_order_count
    FROM orders 
    WHERE customer_id = p_customer_id
    AND status = 'PENDING';
    
    -- Business logic
    IF v_order_count > 0 AND p_new_status = 'INACTIVE' THEN
        RETURN 'ERROR: Cannot deactivate customer with pending orders';
    END IF;
    
    -- Update status
    UPDATE customers 
    SET status = p_new_status,
        last_modified = CURRENT_TIMESTAMP
    WHERE customer_id = p_customer_id;
    
    v_result := 'SUCCESS: Status updated from ' || v_old_status || ' to ' || p_new_status;
    RETURN v_result;
    
EXCEPTION
    WHEN OTHERS THEN
        RETURN 'ERROR: ' || SQLERRM;
END;
$ LANGUAGE plpgsql;"""
        st.code(pg_proc, language="sql")
    
    st.markdown("""
    **üîÑ Conversion Highlights:**
    - Oracle OUT parameters ‚Üí PostgreSQL RETURNS
    - Exception handling adapted to PostgreSQL syntax
    - SYSDATE ‚Üí CURRENT_TIMESTAMP
    - Transaction management adjusted for PostgreSQL
    """)

def show_performance_analysis_demo():
    """Performance analysis and optimization demo"""
    st.subheader("üìä Performance Impact Analysis")
    
    # Create sample performance data
    performance_data = {
        'Migration Scenario': [
            'Simple SELECT with JOINs',
            'Complex Analytics Query', 
            'Stored Procedure Conversion',
            'Large Data Migration',
            'Index Strategy Migration',
            'Trigger Logic Conversion'
        ],
        'Before (Manual Hours)': [2, 8, 12, 16, 6, 10],
        'After (AI-Assisted Hours)': [0.3, 1.2, 1.8, 2.4, 0.9, 1.5],
        'Time Savings': ['85%', '85%', '85%', '85%', '85%', '85%'],
        'Accuracy Rate': ['98%', '94%', '92%', '96%', '95%', '90%'],
        'Performance Gain': ['+15%', '+25%', '+20%', '+10%', '+35%', '+18%']
    }
    
    df = pd.DataFrame(performance_data)
    st.dataframe(df, use_container_width=True)
    
    # ROI Calculation
    col1, col2, col3 = st.columns(3)
    
    total_manual_hours = sum(performance_data['Before (Manual Hours)'])
    total_ai_hours = sum(performance_data['After (AI-Assisted Hours)'])
    time_saved = total_manual_hours - total_ai_hours
    
    with col1:
        st.metric("Total Manual Hours", f"{total_manual_hours}h", f"-{time_saved:.1f}h")
    with col2:
        st.metric("AI-Assisted Hours", f"{total_ai_hours}h", f"85% faster")
    with col3:
        st.metric("Cost Savings", f"${time_saved * 75:,.0f}", "@ $75/hour")
    
    # Performance improvement chart
    st.markdown("#### Query Performance Improvements by Database")
    
    perf_chart_data = {
        'Database': ['PostgreSQL', 'Oracle', 'SQL Server'],
        'Before Migration': [100, 100, 100],
        'After AI Optimization': [125, 135, 120]
    }
    
    chart_df = pd.DataFrame(perf_chart_data)
    st.bar_chart(chart_df.set_index('Database'))

def show_trigger_migration_demo():
    """Trigger migration demo"""
    st.markdown("#### Trigger Logic Migration Example")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**SQL Server Trigger:**")
        sqlserver_trigger = """CREATE TRIGGER trg_audit_customer_changes
ON customers
AFTER UPDATE
AS
BEGIN
    SET NOCOUNT ON;
    
    INSERT INTO customer_audit (
        customer_id,
        old_status,
        new_status,
        changed_by,
        changed_date,
        change_type
    )
    SELECT 
        i.customer_id,
        d.status,
        i.status,
        SYSTEM_USER,
        GETDATE(),
        'UPDATE'
    FROM inserted i
    INNER JOIN deleted d ON i.customer_id = d.customer_id
    WHERE i.status <> d.status;
END;"""
        st.code(sqlserver_trigger, language="sql")
    
    with col2:
        st.markdown("**PostgreSQL Trigger:**")
        postgresql_trigger = """CREATE OR REPLACE FUNCTION audit_customer_changes()
RETURNS TRIGGER AS $
BEGIN
    -- Only audit status changes
    IF OLD.status IS DISTINCT FROM NEW.status THEN
        INSERT INTO customer_audit (
            customer_id,
            old_status,
            new_status,
            changed_by,
            changed_date,
            change_type
        ) VALUES (
            NEW.customer_id,
            OLD.status,
            NEW.status,
            current_user,
            CURRENT_TIMESTAMP,
            'UPDATE'
        );
    END IF;
    
    RETURN NEW;
END;
$ LANGUAGE plpgsql;

CREATE TRIGGER trg_audit_customer_changes
    AFTER UPDATE ON customers
    FOR EACH ROW
    EXECUTE FUNCTION audit_customer_changes();"""
        st.code(postgresql_trigger, language="sql")
    
    st.markdown("""
    **üîÑ Key Conversions:**
    - SQL Server trigger ‚Üí PostgreSQL function + trigger
    - `inserted`/`deleted` tables ‚Üí `NEW`/`OLD` records
    - `SYSTEM_USER` ‚Üí `current_user`
    - `GETDATE()` ‚Üí `CURRENT_TIMESTAMP`
    """)

def show_security_features_demo():
    """Security features migration demo"""
    st.markdown("#### Security Feature Translation")
    
    security_scenarios = st.radio(
        "Select security scenario:",
        ["Row-Level Security", "Column Encryption", "User Privileges"]
    )
    
    if security_scenarios == "Row-Level Security":
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Oracle VPD Policy:**")
            oracle_rls = """-- Oracle Virtual Private Database
CREATE OR REPLACE FUNCTION customer_security_policy(
    schema_var IN VARCHAR2,
    table_var IN VARCHAR2
) RETURN VARCHAR2 AS
BEGIN
    RETURN 'region_id = SYS_CONTEXT(''USER_CTX'', ''REGION_ID'')';
END;

BEGIN
    DBMS_RLS.ADD_POLICY(
        object_schema => 'SALES',
        object_name => 'CUSTOMERS',
        policy_name => 'CUSTOMER_REGION_POLICY',
        function_schema => 'SALES',
        policy_function => 'customer_security_policy',
        statement_types => 'SELECT,UPDATE,DELETE'
    );
END;"""
            st.code(oracle_rls, language="sql")
        
        with col2:
            st.markdown("**PostgreSQL RLS:**")
            postgresql_rls = """-- PostgreSQL Row Level Security
-- Enable RLS on table
ALTER TABLE customers ENABLE ROW LEVEL SECURITY;

-- Create policy function
CREATE OR REPLACE FUNCTION get_user_region()
RETURNS INTEGER AS $
BEGIN
    RETURN current_setting('app.user_region_id')::INTEGER;
EXCEPTION
    WHEN OTHERS THEN
        RETURN NULL;
END;
$ LANGUAGE plpgsql STABLE;

-- Create RLS policy
CREATE POLICY customer_region_policy ON customers
    FOR ALL
    TO application_users
    USING (region_id = get_user_region());

-- Grant permissions
GRANT SELECT, UPDATE, DELETE ON customers TO application_users;"""
            st.code(postgresql_rls, language="sql")

def show_optimization_cases_demo():
    """Optimization cases demo"""
    st.markdown("#### Performance Optimization Cases")
    
    opt_cases = [
        {
            "title": "üéØ Index Strategy Optimization",
            "description": "AI analyzes query patterns and suggests optimal indexing",
            "before": "Manual index analysis: 4-6 hours",
            "after": "AI recommendation: 15 minutes",
            "improvement": "95% time reduction + 30% query performance gain"
        },
        {
            "title": "üîÑ Join Optimization",
            "description": "Converts complex subqueries to efficient joins",
            "before": "Nested subqueries causing table scans",
            "after": "Optimized JOINs with proper indexing",
            "improvement": "60% query performance improvement"
        },
        {
            "title": "üìä Partition Strategy",
            "description": "Recommends optimal partitioning for large tables",
            "before": "Monolithic table structure",
            "after": "Date-based partitioning strategy",
            "improvement": "80% reduction in query time for recent data"
        }
    ]
    
    for case in opt_cases:
        with st.expander(case["title"]):
            st.write(f"**Description:** {case['description']}")
            st.write(f"**Before:** {case['before']}")
            st.write(f"**After:** {case['after']}")
            st.success(f"**Result:** {case['improvement']}")

def show_demo_example(source, target, title, sample_query):
    """Show a demo example for stakeholders"""
    st.subheader(title)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.text(f"Source ({source}):")
        st.code(sample_query[:200] + "...", language="sql")
    
    with col2:
        st.text(f"Target ({target}):")
        st.code("-- Translated query would appear here\n-- with optimizations and comments", language="sql")
    
    # Demo metrics
    metrics_col1, metrics_col2, metrics_col3 = st.columns(3)
    with metrics_col1:
        st.metric("Conversion Rate", "94%")
    with metrics_col2:
        st.metric("Performance Gain", "+35%")
    with metrics_col3:
        st.metric("Time Saved", "8 hours")

def add_to_history(source_query, translated_query, source_db, target_db):
    """Add translation to session history"""
    if 'translation_history' not in st.session_state:
        st.session_state.translation_history = []
    
    entry = {
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'source_db': source_db,
        'target_db': target_db,
        'source_query': source_query[:100] + "..." if len(source_query) > 100 else source_query,
        'success': True
    }
    
    st.session_state.translation_history.append(entry)
    
    # Show history in sidebar
    with st.sidebar:
        if st.session_state.translation_history:
            st.subheader("üìä Translation History")
            df = pd.DataFrame(st.session_state.translation_history[-5:])  # Last 5 translations
            st.dataframe(df[['timestamp', 'source_db', 'target_db', 'success']], 
                        use_container_width=True)

# Sidebar with additional features
def sidebar_features():
    """Additional sidebar features"""
    st.sidebar.markdown("---")
    st.sidebar.header("üéØ ROI Calculator")
    
    # Enhanced ROI calculator for demo
    manual_hours = st.sidebar.number_input("Manual Migration Hours", value=40, min_value=1, max_value=200)
    hourly_rate = st.sidebar.number_input("DBA Hourly Rate ($)", value=75, min_value=50, max_value=200)
    num_queries = st.sidebar.number_input("Number of Queries to Convert", value=150, min_value=1, max_value=1000)
    
    # Calculate savings
    automated_hours = manual_hours * 0.15  # 85% automation
    time_savings = manual_hours - automated_hours
    cost_savings = time_savings * hourly_rate
    
    # Per-query metrics
    manual_time_per_query = (manual_hours * 60) / num_queries  # minutes
    ai_time_per_query = manual_time_per_query * 0.15
    
    st.sidebar.metric("‚è±Ô∏è Time Saved", f"{time_savings:.1f} hours", f"{((time_savings/manual_hours)*100):.0f}% reduction")
    st.sidebar.metric("üí∞ Cost Savings", f"${cost_savings:,.0f}", f"${cost_savings/num_queries:.0f} per query")
    st.sidebar.metric("‚ö° Speed Improvement", f"{manual_time_per_query:.1f}m ‚Üí {ai_time_per_query:.1f}m", "per query")
    
    # Project timeline calculator
    st.sidebar.markdown("---")
    st.sidebar.header("üìÖ Project Timeline")
    
    migration_complexity = st.sidebar.selectbox(
        "Migration Complexity",
        ["Simple (Basic queries)", "Medium (Mixed complexity)", "Complex (Advanced features)"]
    )
    
    complexity_multiplier = {"Simple (Basic queries)": 1.0, "Medium (Mixed complexity)": 1.3, "Complex (Advanced features)": 1.6}
    adjusted_hours = automated_hours * complexity_multiplier[migration_complexity]
    
    st.sidebar.metric("üìä Estimated Timeline", f"{adjusted_hours:.1f} hours", f"{adjusted_hours/8:.1f} days")
    
    # Demo data export
    st.sidebar.markdown("---")
    st.sidebar.header("üìÅ Demo Resources")
    
    if st.sidebar.button("üì• Download Demo Report"):
        # Create demo report data
        report_data = {
            "metric": ["Time Savings", "Cost Savings", "Accuracy Rate", "Performance Gain"],
            "value": [f"{((time_savings/manual_hours)*100):.0f}%", f"${cost_savings:,.0f}", "94%", "+28%"],
            "description": [
                "Reduction in manual effort",
                "Based on DBA hourly rate",
                "Average conversion accuracy",
                "Query performance improvement"
            ]
        }
        df = pd.DataFrame(report_data)
        csv = df.to_csv(index=False)
        st.sidebar.download_button(
            label="üíæ Download CSV Report",
            data=csv,
            file_name="genai_migration_demo_report.csv",
            mime="text/csv"
        )
    
    if st.sidebar.button("üìã Export Query Examples"):
        examples_data = {
            "source_db": ["PostgreSQL", "Oracle", "SQL Server"],
            "target_db": ["Oracle", "SQL Server", "PostgreSQL"],
            "complexity": ["High", "Medium", "High"],
            "estimated_savings": ["6 hours", "4 hours", "8 hours"],
            "success_rate": ["94%", "96%", "92%"]
        }
        df = pd.DataFrame(examples_data)
        csv = df.to_csv(index=False)
        st.sidebar.download_button(
            label="üíæ Download Examples CSV",
            data=csv,
            file_name="query_conversion_examples.csv",
            mime="text/csv"
        )
    
    # Demo controls
    st.sidebar.markdown("---")
    st.sidebar.header("üé¨ Demo Controls")
    
    if st.sidebar.button("üîÑ Reset Demo Data"):
        # Clear session state
        for key in list(st.session_state.keys()):
            if key.startswith('demo_'):
                del st.session_state[key]
        st.sidebar.success("‚úÖ Demo data reset!")
    
    if st.sidebar.button("üìä Show Performance Stats"):
        st.sidebar.json({
            "conversion_rate": "85%",
            "accuracy": "94%",
            "avg_performance_gain": "28%",
            "supported_databases": 3,
            "feature_coverage": "95%"
        })
    
    # Stakeholder presentation mode
    st.sidebar.markdown("---")
    st.sidebar.header("üéØ Presentation Mode")
    
    presentation_mode = st.sidebar.toggle("Enable Presentation Mode", value=False)
    
    if presentation_mode:
        st.sidebar.markdown("""
        <div class="info-banner" style="margin: 0; font-size: 0.9em;">
            <strong>Presentation Mode Activated</strong><br>
            ‚Ä¢ Simplified UI for stakeholder demo<br>
            ‚Ä¢ Focus on key value propositions<br>
            ‚Ä¢ Automated demo scenarios
        </div>
        """, unsafe_allow_html=True)
        
        # Auto-advance demo timer
        demo_timer = st.sidebar.slider("Auto-advance timer (seconds)", 10, 60, 30)
        if st.sidebar.button("‚ñ∂Ô∏è Start Auto Demo"):
            st.sidebar.success(f"Auto demo started! Advancing every {demo_timer}s")
    
    # Stakeholder feedback collection
    st.sidebar.markdown("---")
    st.sidebar.header("üí¨ Feedback")
    
    feedback_rating = st.sidebar.radio(
        "Rate this demo:",
        ["‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent", "‚≠ê‚≠ê‚≠ê‚≠ê Good", "‚≠ê‚≠ê‚≠ê Average", "‚≠ê‚≠ê Below Average", "‚≠ê Poor"]
    )
    
    feedback_text = st.sidebar.text_area("Additional comments:", placeholder="What impressed you most?")
    
    if st.sidebar.button("üì§ Submit Feedback"):
        # In a real app, this would save to a database
        st.sidebar.success("‚úÖ Thank you for your feedback!")
        
    # Contact info
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div class="info-banner" style="margin: 0; font-size: 0.9em; text-align: center;">
        <strong>üöÄ Demo Contact</strong><br>
        üìß database-team@company.com<br>
        üì± +1 (555) 123-4567<br>
        üîó <a href="https://calendly.com/db-team" style="color: #3498db;">Schedule Follow-up Meeting</a>
    </div>
    """, unsafe_allow_html=True)

def show_success_metrics():
    """Display success metrics for stakeholder presentation"""
    if st.sidebar.checkbox("üìà Show Success Metrics"):
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="üéØ Automation Rate",
                value="85%",
                delta="15% above industry average",
                help="Percentage of queries automatically converted"
            )
        
        with col2:
            st.metric(
                label="‚ö° Speed Improvement", 
                value="60%",
                delta="40% faster than manual",
                help="Migration timeline reduction"
            )
        
        with col3:
            st.metric(
                label="‚úÖ Success Rate",
                value="94%",
                delta="9% improvement",
                help="Accuracy of automated conversions"
            )
        
        with col4:
            st.metric(
                label="üí∞ ROI",
                value="320%",
                delta="220% profit",
                help="Return on investment within 6 months"
            )

if __name__ == "__main__":
    main()
    show_success_metrics()
    sidebar_features()